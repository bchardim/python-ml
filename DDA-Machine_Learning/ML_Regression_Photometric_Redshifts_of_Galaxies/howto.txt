###############################
# Links
###############################

+ http://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/tutorial/astronomy/regression.html


####################################
# pip
####################################

# pip install scikit-learn --user
# pip install numpy --upgrade --user



#########################################################
# DD Astronomy - Regresion Classifier Machine Learning
#########################################################

+ astropy.info.net/astropy

+ Decission Tree based

+ regression_classifier.py


Introduction
-------------

+ In this activity, we're going to use decision trees to determine the redshifts of galaxies from their photometric colours. 
  We'll use galaxies where accurate spectroscopic redshifts have been calculated as our gold standard. 
  We will learn how to assess the accuracy of the decision trees predictions and have a look at validation of our model.

  We will also have a quick look at how this problem might be approached without using machine learning. 
  This will highlight some of the limitations of the classical approach and demonstrate why a machine learning approach is ideal for this type of problem.



Magnitudes and colours
----------------------

+ We will be using flux magnitudes from the Sloan Digital Sky Survey (SDSS http://www.sdss.org) catalogue to create colour indices. 
  Flux magnitudes are the total flux (or light) received in five frequency bands (u, g, r, i and z). 

./plot_sdss_filters_11.png


+ The astronomical colour (or colour index) is the difference between the magnitudes of two filters, i.e. u - g or i - z.

+ This index is one way to characterise the colours of galaxies. For example, if the u-g index is high then the object is brighter in ultra violet frequencies than it is in visible green frequencies.

+ Colour indices act as an approximation for the spectrum of the object and are useful for classifying stars into different types.


What data do we need?
---------------------

+ To calculate the redshift of a distant galaxy, the most accurate method is to observe the optical emission lines and measure the shift in wavelength. However, this process can be time consuming and is thus infeasible for large samples.

+ For many galaxies we simply don't have spectroscopic observations.

+ Instead, we can calculate the redshift by measuring the flux using a number of different filters and comparing this to models of what we expect galaxies to look like at different redshifts.

+ In this activity, we will use machine learning to obtain photometric redshifts for a large sample of galaxies. We will use the colour indices (u-g, g-i, r-i and i-z) as our input and a subset of sources with spectroscopic redshifts as the training dataset.
 


Decision tree algorithms
------------------------

+ Decision trees are a tool that can be used for both classification and regression. 
  In this module we will look at regression, however, in the next module we will see how they can be used as classifiers.

+ Decision trees map a set of input features to their corresponding output targets. 
  This is done through a series of individual decisions where each decision represents a node (or branching) of the tree.

+ The following figure shows the decision tree our proverbial robot tennis player Robi used in the lectures to try and decide whether to play tennis on a particular day.


./tennis.png


+ Each node represents a decision that the robot needs to make (or assess) to reach a final decision. 
  In this example, the decision tree will be passed a set of input features (Outlook, Humidity and Wind) and will return an output of whether to play or not.



Decision trees for regression
-----------------------------

+ In decision trees for real-world tasks, each decision is typically more complex, involving measured values, not just categories.

+ Instead of the input values for humidity being Normal or High and wind being Strong or Weak we might see a percentage between 0 and 100 for humidity and a 
  wind speed in km/hr for wind. Our decisions might then be humidity < 40% or wind < 5 km/hr.

+ The output of regression is a real number. So, instead of the two outputs of Play and Don't Play we have a probability of whether we will play that day.

+ The decision at each branch is determined from the training data by the decision tree learning algorithm. 
  Each algorithm employs a different metric (e.g. Gini impurity or information gain) to find the decision that splits the data most effectively.

+ For now, just need to know that a decision tree is a series of decisions, each made on a single feature of the data. 
  The end point of all the branches is a set of desired target values. 



Decision trees in Python
------------------------

+ The inputs to our decision tree are the colour indices from photometric imaging and our output is a photometric redshift. 
  Our training data uses accurate spectroscopic measurements.

+ The decision tree will look something like the following.

./decisiontree_1.png

+ We can see how our calculated colour indices are input as features at the top and through a series of decision nodes a target redshift value is reached and output.

+ We will be using the Python machine learning library scikit-learn (http://scikit-learn.org/stable/) which provides several machine learning algorithms.

+ The scikit-learn decision tree regression takes a set of input features and the corresponding target values, and constructs a decision tree model that can be 
  applied to new data.



Sloan Digital Sky Survey data
-----------------------------

+ We have provided the Sloan data in NumPy binary format (.npy) in a file called sdss_galaxy_colors.npy. 
  The Sloan data is stored in a NumPy structured array and looks like this:

u 	g 	r 	i 	z 	... 	redshift

19.84 	19.53 	19.47 	19.18 	19.11 	... 	0.54
19.86 	18.66 	17.84 	17.39 	17.14 	... 	0.16
... 	... 	... 	... 	... 	... 	...
18.00 	17.81 	17.77 	17.73 	17.73 	... 	0.47


+ It also include spec_class and redshift_err columns we don't need in this activity. The data can be loaded using: 

import numpy as np
data = np.load('sdss_galaxy_colors.npy')
print(data[0])

The data[0] corresponds to the first row of the table above. 
Individual named columns can be accessed like this: 

import numpy as np
data = np.load('sdss_galaxy_colors.npy')
print(data['u'])


Each flux magnitude column can be accessed in the data array as data['u'], data['g'] etc. 
The redshifts can accessed with data['redshift']. 


----------------------------------------------------------------------------------------
LAB - Features and Targets - regression.py
----------------------------------------------------------------------------------------

+  Write a get_features_targets function that splits the training data into input features and their corresponding targets. 
   In our case, the inputs are the 4 colour indices and our targets are the corresponding redshifts.

Your function should return a tuple of:

    - features: a NumPy array of dimensions m ⨉ 4, where m is the number of galaxies;
    - targets: a 1D NumPy array of length m, containing the redshift for each galaxy.

The data argument will be the structured array described on the previous slide. 
The u flux magnitudes and redshifts can be accessed as a column with data['u'] and data['redshift'].

The four features are the colours u - g, g - r, r - i and i - z. 
To calculate the first column of features, subtract the u and g columns, like this:

import numpy as np
data = np.load('sdss_galaxy_colors.npy')
print(data['u'] - data['g'])

The features for the first 2 galaxies in the example data should be:

[[ 0.31476  0.0571   0.28991  0.07192]
 [ 1.2002   0.82026  0.45294  0.24665]]

And the first 2 targets should be:
[ 0.539301   0.1645703] 


+ Hint: set up your features array with zeros

You can set up the features array with zeros and then set each column to the corresponding calculated feature.

features = np.zeros((data.shape[0], 4))
features[:, 0] = data['u'] - data['g']



import numpy as np

def get_features_targets(data):
  features = np.zeros(shape=(len(data), 4))
  features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r']
  features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z']
  targets = data['redshift']
  return features, targets


if __name__ == "__main__":
  # load the data
  data = np.load('sdss_galaxy_colors.npy')
    
  # call our function 
  features, targets = get_features_targets(data)
    
  # print the shape of the returned arrays
  print(features[:2])
  print(targets[:2])




-----------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------
LAB - Decision Tree Regressor - regression.py
-----------------------------------------------------------------------------------------

+ We are now going to use our features and targets to train a decision tree and then make a prediction. 
  We are going to use the DecisionTreeRegressor class from the sklearn.tree module.

  The decision tree regression learning algorithm is initialised with:

dtr = DecisionTreeRegressor()

  We will discuss some optimisations later in the activity, but for now we are just going to use the default values.
  To train the model, we use the fit method with the features and targets we created earlier:

dtr.fit(features, targets)

  The decision tree is now trained and ready to make a prediction:

predictions = dtr.predict(features)

  predictions is an array of predicted values corresponding to each of the input variables in the array.

  Your task is to put this together for our photometric redshift data. 
  Copy your get_features_targets from the previous problem. Use the comments to guide your implementation.

  Finally, print the first 4 predictions. It should print this:

  [ 0.539301    0.1645703   0.04190006  0.04427702]




import numpy as np
from sklearn.tree import DecisionTreeRegressor

# copy in your get_features_targets function here
def get_features_targets(data):
  features = np.zeros(shape=(len(data), 4))
  features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r']
  features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z']
  targets = data['redshift']
  return features, targets

# load the data and generate the features and targets
data = np.load('sdss_galaxy_colors.npy')
features, targets = get_features_targets(data)
  
# initialize model
dtr = DecisionTreeRegressor()

# train the model
dtr.fit(features, targets)

# make predictions using the same features
predictions = dtr.predict(features)

# print out the first 4 predicted redshifts
print(predictions[:4])


------------------------------------------------------------------------------------------



Evaluating our results, accuracy 
--------------------------------

+ So we trained a decision tree! Great...but how do we know if the tree is actually any good at predicting redshifts?

 In regression we compare the predictions generated by our model with the actual values to test how well our model is performing. 
 The difference between the predicted values and actual values (sometimes referred to as residuals) can tell us a lot about where our model is performing well and where it is not.

 While there are a few different ways to characterise these differences, in this tutorial we will use the median of the differences between our predicted and actual values. 
 This is given by:

 med_diff=median(|Yi,pred -Yi,act|)

 Where denotes || the absolute value of the difference.
  


---------------------------------------------------------------------------------------------------
LAB - Calculating the median difference
---------------------------------------------------------------------------------------------------

+ In this problem we will implement the function median_diff. The function should calculate the median residual error of our model, i.e. the median difference between our predicted and actual redshifts.

  The median_diff function takes two arguments – the predicted and actual/target values. 
  When we use this function later in the tutorial, these will corresponding to the predicted redshifts from our decision tree and their corresponding measured/target values.

  The median of differences should be calculated according to the formula: 


  med_diff=median(|Yi,pred -Yi,act|)


import numpy as np


# Write a function that calculates the median of the differences between our predicted and actual values

def median_diff(predicted, actual):
  return np.median(np.abs(predicted[:] - actual[:]))

if __name__ == "__main__":
  # load testing data
  targets = np.load('targets.npy')
  predictions = np.load('predictions.npy')

  # call your function to get the median difference between the predicted values and the target values
  diff = median_diff(predictions, targets)

  # print the median difference
  print("Median difference: {:0.3f}".format(diff))



----------------------------------------------------------------------------------------------------


Evaluating our results, validation
----------------------------------


+ We previously used the same data for training and testing our decision trees.

  This gives an unrealistic estimate of how accurate the model will be on previously unseen galaxies because the model has been optimised to get the best results on the training data.

  The simplest way to solve this problem is to split our data into training and testing subsets:


  # initialise and train the decision tree
  dtr = DecisionTreeRegressor()
  dtr.fit(train_features, train_targets)

  # get a set of prediction from the test input features
  predictions = dtr.predict(test_features)

  # compare the accuracy of the pediction againt the actual values
  print(calculate_rmsd(predictions, test_targets)) 


  + This method of validation is the most basic approach to validation and is called held-out validation. 
    We will use the med_diff accuracy measure and hold-out validation in the next problem to assess the accuracy of our decision tree. 


-------------------------------------------------------------------------------------------------------
LAB - Validating our model
-------------------------------------------------------------------------------------------------------

+  In this problem, we will use median_diff from the previous question to validate the decision tree model. 
   Your task is to complete the validate_model function.

   The function should split the features and targets into train and test subsets, like this 50:50 split for features: 

   split = features.shape[0]//2
   train_features = features[:split]
   test_features = features[split:]


+ Your function should then use the training split (train_features and train_targets) to train the model. 

   Finally, it should measure the accuracy of the model using median_diff on the test_targets and the predicted redshifts from test_features.
   The function should take 3 arguments:

     - model, the decision tree regressor;
     - features, the features for the data set;
     - targets, The targets for the data set.
    

!!! When splitting the features and targets be careful to ensure that the train_features have the correct train_targets, 
   i.e. train_features[0] corresponds to train_targets[0] etc. 


import numpy as np
from sklearn.tree import DecisionTreeRegressor

# paste your get_features_targets function here
def get_features_targets(data):
  features = np.zeros((data.shape[0], 4))
  features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r']
  features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z']
  targets = data['redshift']
  return features, targets

# paste your median_diff function here
def median_diff(predicted, actual):
  return np.median(np.abs(predicted - actual))

# write a function that splits the data into training and testing subsets
# trains the model and returns the prediction accuracy with median_diff
def validate_model(model, features, targets):
  # split the data into training and testing
  split = 2*features.shape[0]//3
  train_features, test_features = features[:split], features[split:]
  train_targets, test_targets = targets[:split], targets[split:]

  # train the model
  model.fit(train_features, train_targets)

  # get the predicted_redshifts
  predictions = model.predict(test_features)  
  
  # use median_diff function to calculate the accuracy
  return median_diff(test_targets, predictions)


if __name__ == "__main__":
  data = np.load('sdss_galaxy_colors.npy')
  features, targets = get_features_targets(data)

  # initialize model
  dtr = DecisionTreeRegressor()

  # validate the model and print the med_diff
  diff = validate_model(dtr, features, targets)
  print('Median difference: {:f}'.format(diff))

--------------------------------------------------------------------------------------------------------


Exploring the output tree
-------------------------

+ But what does the decision tree actually look like? 

./decision_tree.jpg

You can see how the decision is made at each node as well as the number of samples which reach that node. 
We won't go through how to make these plots in the tutorial, but you can download a demo script and data to try at home. 

plot_decision_tree.py


+ The median of differences of =0.02. 
  This means that half of our galaxies have a error in the prediction of <0.02, which is pretty good. 
  One of the reason we chose the median of differences as our accuracy measure is that it gives a fair representation of the errors especially when the distribution of errors is skewed. 
  The graph below shows the distribution of residuals (differences) for our model along with the median and interquartile values. 


residuals.png

+ As you can tell the distribution is very skewed. We have zoomed in here, but the tail of the distribution goes all the way out to 6. 



The effect of training set size
-------------------------------

+ The number of galaxies we use to train the model has a big impact on how accurate our predictions will be. This is the same with most machine learning methods: the more data that they are trained with, the more accurate their prediction will be.

  Here is how our median difference changes with training set size:  

  Trainig Galaxies       median_diff

  50                     0.048
  500                    0.026
  5000                   0.023
  50000                  0.022

+ Understanding how the accuracy of the model changes with sample size is important to understanding the limitations of our model. 
  We are approaching the accuracy limit of the decision tree model (for our redshift problem) with a training sample size of 25,000 galaxies.

+ The only way we could further improve our model would be to use more features. 
  This might include more colour indices or even the errors associated with the measured flux magnitudes.



Before machine learning
-----------------------

+ Before machine learning, we would have tried to solve this problem with regression — by constructing an empirical model to predict how the dependent variable (redshift) 
  varies with one or more independent variables (the colour indices).

  A plot of how the colours change with redshift tells us that it is quite a complex function, for example redshift versus u - g: 
  

+ One approach would be to construct a multi-variate non-linear regression model. Perhaps using a least squares fitting to try and determine the best fit parameters. 
  The model would be quite complex; based on the above plot, a dampened inverse sine function would be a good starting point for such a model.

+ While we could try such an approach the function would be overly complex and there is no guarantee that it would yield very promising results. 
  Another approach would be to plot a colour-index vs colour-index plot using an additional colour scale to show redshift. The following plot is an example of such a plot.  

+ It shows that we get reasonably well defined regions where redshifts are similar. If we were to make a contour map of the redshifts in the colour index vs colour index space 
  we would be able to get an estimate of the redshift for new data points based on a combination of their colour indices. This would lead to redshift estimates with significant 
  uncertainties attached to them.

  In the next problem you will re-create the Colour-index vs Colour-index plot with redshift as colour bar. 



Colour-Colour Redshift Plot
---------------------------  

+ Your task here is simply to try and re-create the following plot. 
  You should use the pyplot module of matplotlib which has already been imported and can be accessed through plt. 
  In particular you can use the plt.scatter() function, with additional arguments s, c and cmap 

  We are interested in the u-g and r-i colour indices.
  You can make use of the plt.colorbar() function to show your scatter plots colour argument(c) to a colour bar on the side of the plot.
  Make sure you implement x and y labels and give your plot a title. 

  plot_color_color_z.py



Summary
-------


+ In this activity, we implemented some decision tree models to help predict the redshift of galaxies based on their measured colour indices. 
  We learnt that there are several ways to assess the accuracy of the model and in our validations we used the median of the residuals.

+ We touched on how the problem might be approached without machine learning and found that there isn't too much available that can be simply used.

+ We also learnt why we need to cross validate the model and that this is done by splitting the data into seperate training and testing subsets. 
  We will look at k-fold cross validation in the next tutorial; where the testing and training are changed to include various combinations of seperate subsets.

+ In the next tutorial we will also explore how decision trees have a tendency to overfit the data.


#########################################################
# DD Astronomy - Improving and evaluating our classifier
#########################################################

+ improved_regression_classifier.py


Introduction
------------

+ In start this activity by looking at how decision trees tend to overfit the data if they are left unchecked. Over fitting the data means they try to account for the outlying 
  data points at the cost of the prediction accuracy of the general trend.

+ We will also look at k-fold cross validation. This is a more robust method of validation than the held-out method we used previously.

+ In k-fold cross validation, we can test every example once. This is done by splitting the data set into k subsets and training/testing the model k times using different combinations 
  of the subsets.

+ Finally, we look at how accurate our model is on QSOs compared with other galaxies. As mentioned in the lectures, QSOs are galaxies that have an Active Galactic Nucleus (AGN). 
  The AGN makes the galaxy brighter and as such they are detectable with the SDSS instruments out to much higher redshifts.

+ We will use the same data set as the first activity and even some of functions we wrote in previous questions.
 
 
Overfitting and tree depth
--------------------------

+ Decision trees have many advantages: they are simple to implement, easy to interpret, the data doesn't require too much preparation, and they are reasonably efficient computationally.

+ Decision trees do have some limitations though, one of the biggest being they tend to over fit the data. What this means is that if they are left unchecked they will create an overly 
  complicated tree that attempts to account for outliers in the data. This comes at the expense of the accuracy of the general trend.

+ Part of the reason for this over-fitting is that the algorithm works by trying to optimise the decision locally at each node. There are ways in which this can be mitigated and in the
  next problem we will see how constraining the number of decision node rows (the tree depth) impacts on the accuracy of our predictions.


Setting a maximum depth
-----------------------

+ In order to see how the tree is overfitting we would like to examine how our decision tree performs for different tree depths. Specifically, we would like to see how it performs on 
  test data compared to the data that was used to train it.

+ Naïvely we'd expect, the deeper the tree, the better it should perform. However, as the model overfits we see a difference in its accuracy on the training data and the more general 
  testing data.

+ We can control the depth of decision tree learned, using an argument to DecisionTreeRegressor. For example, to set the maximum depth to 5:

dtr = DecisionTreeRegressor(max_depth=5)
 


-----------------------------------------------------------------------------------------------------------
LAB- Overfitting Trees
-----------------------------------------------------------------------------------------------------------

+ Complete the function accuracy_by_treedepth. The function should return the median difference for both the testing and training data sets for each of the tree depths in depths.

  accuracy_by_treedepth should take the following arguments:

    - features and targets, (as in previous problems);
    - depths, an array of tree depths to be used as the max_depth of the decision tree regressor.

  Your function should return two lists (or arrays) containing the median_diff values for the predictions made on the training and test sets using the maximum tree depths 
  given by the depths.

  For example, if depths is [3, 5, 7], then your function should return two lists of length 3. You can choose the size of the split between your testing and training data 
 (if in doubt, 50:50 is fine).

  We've included code to plot the differences as a function of tree depths. You should take a moment to familiarise yourself with what each line is doing. 


-------------------------------------------------------------------------------------------------------------


Discussion of results
---------------------

+ We can see that the accuracy of the decision tree on the training set gets better as we allow the tree to grow to greater depths. In fact, at a depth of 27 our errors goes to zero!

+ Conversly, the accuracy measure of the predictions for the test set gets better initially and then worse at larger tree depths. At a tree depth ~19 the decision tree starts to overfit
  the data. This means it tries to take into account outliers in the training set and loses its general predictive accuracy.

+ Overfitting is a common problem with decision trees and can be circumvented by adjusting parameters like the tree depth or setting a minimum number of cases at each node. 
  For now, we will set a maximum tree depth of 19 to prevent over-fitting in our redshift problem.  



Cross Validation
----------------


+ The method we used to validate our model so far is known as hold-out validation. Hold out validation splits the data in two, one set to test with and the other to train with. 
  Hold out validation is the most basic form of validation.

+ While hold-out validation is better than no validation, the measured accuracy (i.e. our median of differences) will vary depending on how we split the data into testing and 
  training subsets. The med_diff that we get from one randomly sampled training set will vary to that of a different random training set of the same size.

+ In order to be more certain of our models accuracy we should use k-fold cross validation. k-fold validation works in a similar way to hold-out except that we split the data into subsets. 
  We train and test the model k times, recording the accuracy each time. Each time we use a different combination of k-1 subsets to train the model and the final kth subset to test. 
  We take the average of the accuracy measurements to be the overall accuracy of the the model.


==> KFold

+ The KFold library is designed to split the data into training and testing subsets. It does this by offering an iterable object that can be initialised with

kf = KFold(n_splits=k, shuffle=True)

  The n_splits=k specifies the number of subsets to use.

+ By default shuffle is set to false. It is generally good practice to shuffle the data for cross validation as sometimes during collection and storage, data of a similar type can
  be stored adjacently which would lead to some learning bias when training the tree. For example, if the data was sorted by redshift, on the first iteration the model might be trained 
  with redshifts 0 to 3 and tested on galaxies with redshifts ~4.

+ In the next couple of problems we will use the sklearn library KFold to help us split our data into our k-1 training subsets and remaining test subset. In the first problem we will use the
  convenience of KFolds to help us calculate the k-fold cross validated accuracy of our model. In the second we will extend this to provide a k-folded cross validated prediction for 
  every galaxy in our data set. 


-------------------------------------------------------------------------------------------------------------
LAB - KFold Cross Validation
-------------------------------------------------------------------------------------------------------------


+ Your task is to complete the function cross_validate_model. The function takes 4 arguments:

    - model, feaures, and targets as in previous problems;
    - k in our k-fold. This is the number of subsets to train and test.

  Your function should return a list containing the k median of differences for each of the k folds using median_diff.
  Note that we have set the max_depth=19 when we initialise the decision tree to prevent the model from overfitting.

==>KFolds usage

+ We have created the KFold object to give you a set of training and testing indices for each of the k runs. It is worth taking a moment to understand this.
  Specifically, the object is initialised with

kf = KFold(n_splits=k, shuffle=True)

  The n_splits=k passes our desired number of subsets/folds. We want to shuffle the data (as previously explained). The iterator is then used with:

for train_indices, test_indices in kf.split(features):

  The kf.split(features) is an iterator that, for each of the k iterations, returns two arrays of indices to be used with our feature and target arrays,
  i.e. features[train_indices],targets[train_indices]



import numpy as np
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeRegressor

# paste your get_features_targets function here
def get_features_targets(data):
  features = np.zeros((data.shape[0], 4))
  features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r']
  features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z']
  targets = data['redshift']
  return features, targets

# paste your median_diff function here
def median_diff(predicted, actual):
  return np.median(np.abs(predicted - actual))

# complete this function
def cross_validate_model(model, features, targets, k):
  kf = KFold(n_splits=k, shuffle=True)

  # initialise a list to collect median_diffs for each iteration of the loop below
  diffs = []

  for train_indices, test_indices in kf.split(features):
    train_features, test_features = features[train_indices], features[test_indices]
    train_targets, test_targets = targets[train_indices], targets[test_indices]
    
    # fit the model for the current set
    model.fit(train_features, train_targets)
    
    # predict using the model
    predictions = model.predict(test_features)
 
    # calculate the median_diff from predicted values and append to results array
    diffs.append(median_diff(predictions, test_targets))
 
  # return the list with your median difference values
  return diffs


if __name__ == "__main__":
  data = np.load('./sdss_galaxy_colors.npy')
  features, targets = get_features_targets(data)

  # initialize model with a maximum depth of 19
  dtr = DecisionTreeRegressor(max_depth=19)

  # call your cross validation function
  diffs = cross_validate_model(dtr, features, targets, 10)

  # Print the values
  print('Differences: {}'.format(', '.join(['{:.3f}'.format(val) for val in diffs])))
  print('Mean difference: {:.3f}'.format(np.mean(diffs)))


---------------------------------------------------------------------------------------------------------------


Cross validation of predictions
-------------------------------

+ Cross validation is an important part of ensuring that our model is returning values that are at least partially accurate. 
  The problem with held-out validation is that the we are only able to get prediction values for the data in our test set.

+ With k-fold cross validation each galaxy is tested at least once and because of this we are able to get a prediction value for every galaxy. We'll do this in the next question...
 

------------------------------------------------------------------------------------------------------------------
LAB - KFold Cross Validated Predictions 
------------------------------------------------------------------------------------------------------------------

+ Complete the function cross_validate_predictions. 
  This is very similar to the previous question except instead of returning the med_diff accuracy measurements we would like to return a predicted value for each of the galaxies.

  The function takes the same 4 arguments as the previous question, i.e. model, feaures, targets and k.
  Your function should return a single variable. The returned variable should be a 1-D numpy array of length m, where m is the number of galaxies in our data set. 
  You should make sure that you maintain the order of galaxies when giving your predictions, such that the first prediction in your array corresponds to the first galaxy in the 
  features and targets arrays.
 

+ This is very similar to the previous problem. Here instead of using the predicted values for calculating the accuracy we simply put them into an array which the function returns. 
  We initialise an array to store the predictions from each validation with...

all_predictions = np.zeros(shape = (len(targets)))

  We then use the test_indices to keep the correct order when populating the array.

all_predictions[test_indices] = predicted

  This ensures that we can compare the predictions their corresponding target values later when calculating the median difference and plotting the predicted values against actual values.



import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeRegressor

# paste your get_features_targets function here
def get_features_targets(data):
  features = np.zeros((data.shape[0], 4))
  features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r']
  features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z']
  targets = data['redshift']
  return features, targets

# paste your median_diff function here
def median_diff(predicted, actual):
  return np.median(np.abs(predicted - actual))

# complete this function
def cross_validate_predictions(model, features, targets, k):
  kf = KFold(n_splits=k, shuffle=True)

  # declare an array for predicted redshifts from each iteration
  all_predictions = np.zeros_like(targets)

  for train_indices, test_indices in kf.split(features):
    # split the data into training and testing
    train_features, test_features = features[train_indices], features[test_indices]
    train_targets, test_targets = targets[train_indices], targets[test_indices]
    
    # fit the model for the current set
    model.fit(train_features, train_targets)
        
    # predict using the model
    predictions = model.predict(test_features)
        
    # put the predicted values in the all_predictions array defined above
    all_predictions[test_indices] = predictions

  # return the predictions
  return all_predictions


if __name__ == "__main__":
  data = np.load('./sdss_galaxy_colors.npy')
  features, targets = get_features_targets(data)

  # initialize model
  dtr = DecisionTreeRegressor(max_depth=19)

  # call your cross validation function
  predictions = cross_validate_predictions(dtr, features, targets, 10)

  # calculate and print the rmsd as a sanity check
  diffs = median_diff(predictions, targets)
  print('Median difference: {:.3f}'.format(diffs))

  # plot the results to see how well our model looks
  plt.scatter(targets, predictions, s=0.4)
  plt.xlim((0, targets.max()))
  plt.ylim((0, predictions.max()))
  plt.xlabel('Measured Redshift')
  plt.ylabel('Predicted Redshift')
  plt.show()


--------------------------------------------------------------------------------------------------------------------


K-Fold discussion
-----------------

+ K-Fold cross validation is an important part of assessing the accuracy of any machine learning model. 
  When we plotted our predicted vs measured redshifts we are able to see that for many our galaxies we were able to get a reasonably accurate prediction of redshift. 
  However, there are also several outliers where our model does not give a good prediction.  


+ We have learnt the inner workings of k-Fold cross validation with the help of the KFold library. 
  Now that you have a working understanding of k-Fold you should be aware that there are several methods and libraries in the sklearn.model_selection modules that provide off the shelf 
  versions of some of the routines that we have just written.  

+  The cross_val_predict function performs the same actions as the cross_validate_predictions function you wrote in the previous question. It can be called with:

predictions = cross_val_predict(dtr, features, targets, cv=k)

  Where dtr is our decision tree regressor object, cv=k allows us to specify the number of folds(k) to use and features /targets are as we have used them so far. 

+ There is one other tool in the sklearn.model_selection library that is worth noting, the cross_val_score function. 
  This provides a score of how well the model performed similar to the med_diff we have been using so far. 
  We will not go into the usage here, but you need to specify which metric is used to score the model. 



QSOs vs Galaxies
----------------

+ You might be surprised to learn that our sample of galaxies consists of two different populations: regular galaxies and quasi-stellar objects (QSOs). 
  QSOs are a type of galaxy that contain an actively (and intensly) accreting supermassive black hole. This is often referred to as an Active Galactic Nucleus (AGN).  

+ The light emitted from the AGN is significantly brighter than the rest of the galaxy and we are able to detect these QSOs out to much higher redshifts. 
  In fact, most of the normal galaxies we have been using to create our models have redshifts less than z=0.4, while the QSOs have redshifts all the way out to z=6. 
  Due to this contribution from the AGN, the flux magnitudes measured at different wavelengths might not follow the typical profile we assumed when predicting redshifts.

+ In the next question we are going look at whether there is a difference in the accuracy of the decision trees between QSOs and regular galaxies. 


------------------------------------------------------------------------------------------------------------
LAB - QSO and Galaxy
-------------------------------------------------------------------------------------------------------------

+ Write a function split_galaxies_qsos that splits our data containing both galaxies and QSOs into two arrays that contain only galaxies and QSOs respectively. 
  Your function should take a single data argument.

  The function should return two NumPy arrays, the first galaxies containing only rows from data that are galaxies and the second qsos containing only rows that are QSOs.
  The data array contains a column data['spec_class'] where the values will either be b'GALAXY' or b'QSO'.

!!! 
The spectral class is stored as byte string (not Unicode str), so the literals must have a b out the front. Comparing against 'GALAXY' will not match any rows, whereas b'GALAXY' will 

We can use masking to select particular rows:

import numpy as np
data = np.load('sdss_galaxy_colors.npy')
galaxies = data[data['spec_class'] == b'GALAXY']

The inner data['spec_class'] == b'GALAXY' returns all of the indices that have a galaxy spectral type. These indices are then used to select the rows with the outer data[...]. 

import numpy as np
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeRegressor

# paste your get_features_targets function here
def get_features_targets(data):
  features = np.zeros((data.shape[0], 4))
  features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r']
  features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z']
  targets = data['redshift']
  return features, targets

# paste your median_diff function here
def median_diff(predicted, actual):
  return np.median(np.abs(predicted - actual))

# paste your cross_validate_model function here
def cross_validate_model(model, features, targets, k):
  kf = KFold(n_splits=k, shuffle=True)

  # initialise a list to collect median_diffs for each iteration of the loop below
  diffs = []

  for train_indices, test_indices in kf.split(features):
    train_features, test_features = features[train_indices], features[test_indices]
    train_targets, test_targets = targets[train_indices], targets[test_indices]
    
    # fit the model for the current set
    model.fit(train_features, train_targets)
    
    # predict using the model
    predictions = model.predict(test_features)
 
    # calculate the median_diff from predicted values and append to results array
    diffs.append(median_diff(predictions, test_targets))
 
  # return the list with your median difference values
  return diffs

# complete this function
def split_galaxies_qsos(data):
  # split the data into galaxies and qsos arrays
  galaxies = data[data['spec_class'] == b'GALAXY']
  qsos = data[data['spec_class'] == b'QSO']

  # return the seperated galaxies and qsos arrays
  return galaxies, qsos

def cross_validate_median_diff(data):
  features, targets = get_features_targets(data)
  dtr = DecisionTreeRegressor(max_depth=19)
  return np.mean(cross_validate_model(dtr, features, targets, 10))

if __name__ == "__main__":
  data = np.load('./sdss_galaxy_colors.npy')

  # split the data set into galaxies and QSOs
  galaxies, qsos= split_galaxies_qsos(data)

  # here we cross validate the model and get the cross-validated median difference
  # the cross_validated_med_diff function is in "written_functions"
  galaxy_med_diff = cross_validate_median_diff(galaxies)
  qso_med_diff = cross_validate_median_diff(qsos)

  # print the results
  print("Median difference for Galaxies: {:.3f}".format(galaxy_med_diff))
  print("Median difference for QSOs: {:.3f}".format(qso_med_diff))


--------------------------------------------------------------------------------------------------------------


QSO Discussion
--------------

+ So our QSOs have a greater median residual (0.074) than the galaxies (0.016). There are a couple of possibilities why this is the case.

    - There are far fewer QSOs (8525) than galaxies (41,475).
    - Galaxies aren't as bright as QSOs so they become too faint to be detected with SDSS at redshifts 0.4. This creates a measurement bias.

+ When I take a random sample of galaxies the same size as the QSO data set I get a med_diff of 0.018 which is slightly higher than the full set, but not enough to account 
  for the gap between the two populations.

+ We can see that the majority of galaxies form a peak around 0.10 while the QSOs are resonably evenly distributed out to redshift 2.5. 
  This can lead to a measurement bias. In the case of the galaxies we have trained our decision tree with target redshifts approximately less than 0.4. 
  As such the predictions from this model will not be larger than the maximum target value. So the maximum difference (or residual) for each galaxy in this set will be 
  a lot smaller than the maximum residual for the QSOs. 


Summary
-------

+ We have looked at how decision trees are prone to overfitting the model and how limiting the maximum depth of the tree can be used to prevent this. 
  By comparing the accuracy of the model on the training set with that of the test set for different tree depths we found that a maximum tree depth of 19 was suitable for our model.

+ We looked at k-fold cross validation and the various methods that can be used to implement it. k-fold cross validation mitigates the risk that the training set has a unique 
  or specific population of the data set; For example if all the training data contained QSOs and the testing set regular galaxies. k-folds cross validation also allows you to get 
  a prediction for all the points in your data set.

+ We concluded by looking at the sub-population of QSOs and how their accuracy measurement was significantly worse than that of the other galaxies. 
  On closer inspection we found that this was a measurement bias resulting from the difference in the range of redshifts in each population.

+ You have hopefully learnt all the tools necessary to implement a decision tree on a regression problem of your own. 
  In the next module we will look at how decision trees can be used for classification. We will be using them to classify galaxies as either an elliptical, a spiral or a merger.


 


